# -*- coding: utf-8 -*-
"""EDU-TUTOR.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yrM2RbqwfQ-CJWhM8SQMnPb2FBQOiWQK
"""

# âœ… Step 1: Install Required Libraries
!pip install transformers accelerate gradio --quiet

# âœ… Step 2: Import Libraries
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch
import gradio as gr

# âœ… Step 3: Hugging Face Access Token
HF_TOKEN = "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"  # ðŸ”’ Replace with your Hugging Face token

# âœ… Step 4: Load IBM Granite Model
model_id = "ibm-granite/granite-3.3-2b-instruct"

tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=HF_TOKEN)

model = AutoModelForCausalLM.from_pretrained(
    model_id,
    torch_dtype=torch.float16,       # Run efficiently on T4 GPU
    device_map="auto",
    use_auth_token=HF_TOKEN
)

# âœ… Step 5: Define Edu-Tutor Function
def edu_tutor_advanced(query):
    system_prompt = (
        "You are Edu-Tutor, a highly knowledgeable and articulate AI tutor for higher education. "
        "Respond with clear, structured, and in-depth answers suitable for university-level learners. "
        "Use headings, bullet points, formulas, examples, and references where applicable. Be precise and insightful."
    )

    prompt = f"""### System:
{system_prompt}

### Student:
{query}

### Edu-Tutor:"""

    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)

    outputs = model.generate(
        **inputs,
        max_new_tokens=800,     # Increase to give full explanations
        temperature=0.7,        # Balanced creativity and coherence
        top_p=0.95,
        do_sample=True,
        pad_token_id=tokenizer.eos_token_id
    )

    decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)

    # Extract response from Edu-Tutor section
    if "### Edu-Tutor:" in decoded_output:
        return decoded_output.split("### Edu-Tutor:")[1].strip()
    else:
        return decoded_output.strip()

# âœ… Step 6: Launch Gradio Interface
iface = gr.Interface(
    fn=edu_tutor_advanced,
    inputs=gr.Textbox(lines=4, label="ðŸŽ“ Ask Your Advanced-Level Question"),
    outputs="text",
    title="ðŸŽ“ Edu-Tutor AI (Advanced Academic Assistant)",
    description="Ask deep questions in science, engineering, commerce, humanities, or tech. This AI tutor gives structured and high-level responses powered by IBM Granite 3.3B."
)

# âœ… Step 7: Run App
iface.launch(share=True)